[{"authors":["何宇轩"],"categories":null,"content":"厦门大学系统与软件安全实验室硕士研究生，研究方向主要为静态程序分析。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"9bd42cf6f37850cf1c38c27e6d31d038","permalink":"https://s-cube-xmu.github.io/zh/author/%E4%BD%95%E5%AE%87%E8%BD%A9/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E4%BD%95%E5%AE%87%E8%BD%A9/","section":"authors","summary":"厦门大学系统与软件安全实验室硕士研究生，研究方向主要为静态程序分析。","tags":null,"title":"何宇轩","type":"authors"},{"authors":["刘兀"],"categories":null,"content":"厦门大学系统与软件安全实验室硕士研究生。研究方向主要包括软件测试与程序分析。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"d3611c653e0d51baee7e14d7bd02ac27","permalink":"https://s-cube-xmu.github.io/zh/author/%E5%88%98%E5%85%80/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E5%88%98%E5%85%80/","section":"authors","summary":"厦门大学系统与软件安全实验室硕士研究生。研究方向主要包括软件测试与程序分析。","tags":null,"title":"刘兀","type":"authors"},{"authors":["吴聪霞"],"categories":null,"content":"厦门大学系统与软件安全实验室硕士研究生。研究方向主要包括软件生态系统管理和软件安全。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"98ae106f57d6d7175ef137c68f74ba19","permalink":"https://s-cube-xmu.github.io/zh/author/%E5%90%B4%E8%81%AA%E9%9C%9E/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E5%90%B4%E8%81%AA%E9%9C%9E/","section":"authors","summary":"厦门大学系统与软件安全实验室硕士研究生。研究方向主要包括软件生态系统管理和软件安全。","tags":null,"title":"吴聪霞","type":"authors"},{"authors":["吴荣鑫"],"categories":null,"content":"我目前是厦门大学计算机科学与技术系的副教授。我的研究兴趣包括软件安全、程序分析和软件工程。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"0fde74c834f74ab4f7327f49507d7edc","permalink":"https://s-cube-xmu.github.io/zh/author/%E5%90%B4%E8%8D%A3%E9%91%AB/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E5%90%B4%E8%8D%A3%E9%91%AB/","section":"authors","summary":"我目前是厦门大学计算机科学与技术系的副教授。我的研究兴趣包括软件安全、程序分析和软件工程。","tags":null,"title":"吴荣鑫","type":"authors"},{"authors":["姜瑞霖"],"categories":null,"content":"厦门大学系统与软件安全实验室硕士研究生。研究方向为静态分析与软件安全。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"47066dc87d84591414c7016e9242b8ea","permalink":"https://s-cube-xmu.github.io/zh/author/%E5%A7%9C%E7%91%9E%E9%9C%96/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E5%A7%9C%E7%91%9E%E9%9C%96/","section":"authors","summary":"厦门大学系统与软件安全实验室硕士研究生。研究方向为静态分析与软件安全。","tags":null,"title":"姜瑞霖","type":"authors"},{"authors":["张赫"],"categories":null,"content":"厦门大学系统与软件安全实验室硕士研究生。研究方向主要为静态程序分析。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"186a932778433e14eb2c851be45fad70","permalink":"https://s-cube-xmu.github.io/zh/author/%E5%BC%A0%E8%B5%AB/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E5%BC%A0%E8%B5%AB/","section":"authors","summary":"厦门大学系统与软件安全实验室硕士研究生。研究方向主要为静态程序分析。","tags":null,"title":"张赫","type":"authors"},{"authors":["戚鹏宇"],"categories":null,"content":"厦门大学系统与软件安全实验室硕士研究生。研究方向主要包括构建加速。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"83f94e8536608129d418505c972a9c40","permalink":"https://s-cube-xmu.github.io/zh/author/%E6%88%9A%E9%B9%8F%E5%AE%87/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E6%88%9A%E9%B9%8F%E5%AE%87/","section":"authors","summary":"厦门大学系统与软件安全实验室硕士研究生。研究方向主要包括构建加速。","tags":null,"title":"戚鹏宇","type":"authors"},{"authors":["林立"],"categories":null,"content":"厦门大学系统与软件安全实验室硕士研究生。研究方向主要包括软件生态系统管理, 数据库漏洞检测。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"018f429df1f1c816340d101993ebde79","permalink":"https://s-cube-xmu.github.io/zh/author/%E6%9E%97%E7%AB%8B/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E6%9E%97%E7%AB%8B/","section":"authors","summary":"厦门大学系统与软件安全实验室硕士研究生。研究方向主要包括软件生态系统管理, 数据库漏洞检测。","tags":null,"title":"林立","type":"authors"},{"authors":["王壮达"],"categories":null,"content":"厦门大学系统与软件安全实验室本科生。正在积极成长。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"2b1bbbce871972107f98cd425bafec93","permalink":"https://s-cube-xmu.github.io/zh/author/%E7%8E%8B%E5%A3%AE%E8%BE%BE/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E7%8E%8B%E5%A3%AE%E8%BE%BE/","section":"authors","summary":"厦门大学系统与软件安全实验室本科生。正在积极成长。","tags":null,"title":"王壮达","type":"authors"},{"authors":["王超"],"categories":null,"content":"厦门大学系统与软件安全实验室博士研究生。研究方向主要包括软件生态系统管理, 软件安全和软件测试.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"d2a3006e600c35030d03dfe72fbb1c5f","permalink":"https://s-cube-xmu.github.io/zh/author/%E7%8E%8B%E8%B6%85/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E7%8E%8B%E8%B6%85/","section":"authors","summary":"厦门大学系统与软件安全实验室博士研究生。研究方向主要包括软件生态系统管理, 软件安全和软件测试.","tags":null,"title":"王超","type":"authors"},{"authors":["田紫格"],"categories":null,"content":"厦门大学系统与软件安全实验室硕士研究生。研究方向主要包括构建修复和软件安全。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"a64439281c6ccd8e16ce2cba2106280c","permalink":"https://s-cube-xmu.github.io/zh/author/%E7%94%B0%E7%B4%AB%E6%A0%BC/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E7%94%B0%E7%B4%AB%E6%A0%BC/","section":"authors","summary":"厦门大学系统与软件安全实验室硕士研究生。研究方向主要包括构建修复和软件安全。","tags":null,"title":"田紫格","type":"authors"},{"authors":["胡家欣"],"categories":null,"content":"厦门大学系统与软件安全实验室博士研究生。研究方向主要包括高性能计算、深度学习、软件测试。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"39dbbcaa42745087bdfdcb99c1c9ff20","permalink":"https://s-cube-xmu.github.io/zh/author/%E8%83%A1%E5%AE%B6%E6%AC%A3/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E8%83%A1%E5%AE%B6%E6%AC%A3/","section":"authors","summary":"厦门大学系统与软件安全实验室博士研究生。研究方向主要包括高性能计算、深度学习、软件测试。","tags":null,"title":"胡家欣","type":"authors"},{"authors":["郝宗寅"],"categories":null,"content":"厦门大学系统与软件安全实验室博士研究生。研究方向主要包括软件缺陷定位, 软件测试与构建加速。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"78574b1752f3b97823f8a9bffb44c92d","permalink":"https://s-cube-xmu.github.io/zh/author/%E9%83%9D%E5%AE%97%E5%AF%85/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E9%83%9D%E5%AE%97%E5%AF%85/","section":"authors","summary":"厦门大学系统与软件安全实验室博士研究生。研究方向主要包括软件缺陷定位, 软件测试与构建加速。","tags":null,"title":"郝宗寅","type":"authors"},{"authors":["陈豪尔"],"categories":null,"content":"厦门大学系统与软件安全实验室硕士研究生。研究方向主要包括软件克隆检测和缺陷检测。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"834b487b9af7f0e22e988f843cf3bf17","permalink":"https://s-cube-xmu.github.io/zh/author/%E9%99%88%E8%B1%AA%E5%B0%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E9%99%88%E8%B1%AA%E5%B0%94/","section":"authors","summary":"厦门大学系统与软件安全实验室硕士研究生。研究方向主要包括软件克隆检测和缺陷检测。","tags":null,"title":"陈豪尔","type":"authors"},{"authors":["黄嘉峰"],"categories":null,"content":"厦门大学系统与软件安全实验室硕士研究生。研究方向主要包括代码克隆检测, 第三方库漏洞检测与漏洞API可达性分析。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"f59585f9ae73b0db59fa08be007420b3","permalink":"https://s-cube-xmu.github.io/zh/author/%E9%BB%84%E5%98%89%E5%B3%B0/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E9%BB%84%E5%98%89%E5%B3%B0/","section":"authors","summary":"厦门大学系统与软件安全实验室硕士研究生。研究方向主要包括代码克隆检测, 第三方库漏洞检测与漏洞API可达性分析。","tags":null,"title":"黄嘉峰","type":"authors"},{"authors":["黄志凌"],"categories":null,"content":"厦门大学系统与软件安全实验室硕士研究生。研究方向主要包括构建修复。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"d4d122f1306aa8522acbfb2ae6ffeb0a","permalink":"https://s-cube-xmu.github.io/zh/author/%E9%BB%84%E5%BF%97%E5%87%8C/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E9%BB%84%E5%BF%97%E5%87%8C/","section":"authors","summary":"厦门大学系统与软件安全实验室硕士研究生。研究方向主要包括构建修复。","tags":null,"title":"黄志凌","type":"authors"},{"authors":["黄泉锋"],"categories":null,"content":"厦门大学系统与软件安全实验室硕士研究生。研究方向主要包括缺陷定位，克隆检查。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"6a7e3bd15eeaa1ad218a558d9fc2e6cd","permalink":"https://s-cube-xmu.github.io/zh/author/%E9%BB%84%E6%B3%89%E9%94%8B/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E9%BB%84%E6%B3%89%E9%94%8B/","section":"authors","summary":"厦门大学系统与软件安全实验室硕士研究生。研究方向主要包括缺陷定位，克隆检查。","tags":null,"title":"黄泉锋","type":"authors"},{"authors":[],"categories":null,"content":"Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://s-cube-xmu.github.io/zh/event/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/zh/event/example/","section":"event","summary":"An example event.","tags":[],"title":"Example Event","type":"event"},{"authors":null,"categories":null,"content":"","date":1690848e3,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1690848e3,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://s-cube-xmu.github.io/zh/contact/","publishdate":"2023-08-01T00:00:00Z","relpermalink":"/zh/contact/","section":"","summary":"","tags":null,"title":"Contact","type":"landing"},{"authors":["Zongyin Hao","Quanfeng Huang","Chengpeng Wang","Jianfeng Wang","Yushan Zhang","Rongxin Wu","Charles Zhang"],"categories":null,"content":" ","date":1688947200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1688947200,"objectID":"89d5d46f70a2b9e63cafe6fbd9be0a7c","permalink":"https://s-cube-xmu.github.io/zh/publication/pinolo/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/zh/publication/pinolo/","section":"publication","summary":"DBMSs (Database Management Systems) are essential in modern enterprise software. Thus, ensuring the correctness of DBMSs is critical for enterprise applications. Among various kinds of bugs, logical bugs, which make a DBMS return an incorrect result set for a given SQL query, are the most challenging for detection since they typically do not result in apparent manifestations (e.g., crashes) and are likely to go unnoticed by users. The key challenge of detecting logical bugs is the test oracle problem, i.e., how to automatically characterize the expected results for a given query. The state-of-theart approaches focus on generating the equivalent forms of queries via the customized rules, which rewrite a seed query to achieve the equivalent transformation. This dramatically limits the forms of SQL queries fed to the DBMS and thus leads to the under-reporting of many deeply-hidden logical bugs. In this paper, we propose a novel approach, PINOLO, to constructing a test oracle for logical bugs. Instead of generating the equivalent mutants of a seed query, our idea is to synthesize the queries that theoretically should return a superset or a subset of the result set of the seed query, forming the over-approximations or under-approximations of the seed query. A logical bug is detected if the result set returned by our synthesized query does not follow the expected approximation relation. We implemented our idea as a DBMS testing system and evaluated it on four widely-used DBMSs: MySQL, MariaDB, TiDB, and OceanBase. By the time of writing, PINOLO has found 41 unique logical bugs in these DBMSs, 39 of which have been confirmed by developers.","tags":["DBMS","Logical bug"],"title":"Pinolo: Detecting Logical Bugs in Database Management Systems with Approximate Query Synthesis","type":"publication"},{"authors":null,"categories":null,"content":"Our database defect detection work has been accepted by ATC 2023.\nDetails of publications → ","date":1688169600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1688169600,"objectID":"c635a2bcf1d9a2a7ae2bea24dd16eb6a","permalink":"https://s-cube-xmu.github.io/zh/post/atc2023/","publishdate":"2023-07-01T00:00:00Z","relpermalink":"/zh/post/atc2023/","section":"post","summary":"Our database defect detection work has been accepted by ATC 2023.\n","tags":null,"title":"Our database defect detection work has been accepted by ATC 2023","type":"post"},{"authors":["Haoxiang Jia","Ming Wen","Zifan Xie","Xiaochen Guo","Rongxin Wu","Maolin Sun","Kang Chen","Hai Jin"],"categories":null,"content":" ","date":1684022400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1684022400,"objectID":"5700c05f4503c30d0f360bbba7e6bdf6","permalink":"https://s-cube-xmu.github.io/zh/publication/detecting-jvm-jit-compiler-bugs-2023/","publishdate":"2023-07-14T00:00:00Z","relpermalink":"/zh/publication/detecting-jvm-jit-compiler-bugs-2023/","section":"publication","summary":"Java Virtual Machine (JVM) is the fundamental software system that supports the interpretation and execution of Java bytecode. To support the surging performance demands for the increasingly complex and large-scale Java programs, Just-In-Time (JIT) compiler was proposed to perform sophisticated runtime optimization. However, this inevitably induces various bugs, which are becoming more pervasive over the decades and can often cause significant consequences. To facilitate the design of effective and efficient testing techniques to detect JIT compiler bugs. This study first performs a preliminary study aiming to understand the characteristics of JIT compiler bugs and the corresponding triggering test cases. Inspired by the empirical findings, we propose JOpFuzzer, a new JVM testing approach with a specific focus on JIT compiler bugs. The main novelty of JOpFuzzer is embodied in three aspects. First, besides generating new seeds, JOpFuzzer also searches for diverse configurations along the new dimension of optimization options. Second, JOpFuzzer learns the correlations between various code features and different optimization options to guide the process of seed mutation and option exploration. Third, it leverages the profile data, which can reveal the program execution information, to guide the fuzzing process. Such nov-elties enable JOpFuzzer to effectively and efficiently explore the two-dimensional input spaces. Extensive evaluation shows that JOpFuzzer outperforms the state-of-the-art approaches in terms of the achieved code coverages. More importantly, it has detected 41 bugs in OpenJDK, and 25 of them have already been confirmed or fixed by the corresponding developers.","tags":["JVM","JIT Compiler","JVM Testing"],"title":"Detecting JVM JIT Compiler Bugs via Exploring Two-Dimensional Input Spaces","type":"publication"},{"authors":["Sicong Cao","Xiaobing Sun","Xiaoxue Wu","Lili Bo","Bin Li","Rongxin Wu","Wei Liu","Biao He","Yu Ouyang","Jiajia Li"],"categories":null,"content":" ","date":1684022400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1684022400,"objectID":"213d15251de2139655a34ce99685baec","permalink":"https://s-cube-xmu.github.io/zh/publication/improving-java-deserialization-gadget-chain-mining-2023/","publishdate":"2023-07-14T00:00:00Z","relpermalink":"/zh/publication/improving-java-deserialization-gadget-chain-mining-2023/","section":"publication","summary":"Java (de)serialization is prone to causing security-critical vulnerabilities that attackers can invoke existing methods (gadgets) on the application's classpath to construct a gadget chain to perform malicious behaviors. Several techniques have been proposed to statically identify suspicious gadget chains and dynamically generate injection objects for fuzzing. However, due to their incomplete support for dynamic program features (e.g., Java runtime polymorphism) and ineffective injection object generation for fuzzing, the existing techniques are still far from satisfactory. In this paper, we first performed an empirical study to investigate the characteristics of Java deserialization vulnerabilities based on our manually collected 86 publicly known gadget chains. The empirical results show that 1) Java deserialization gadgets are usually exploited by abusing runtime polymorphism, which enables attackers to reuse serializable overridden methods; and 2) attackers usually invoke exploitable overridden methods (gadgets) via dynamic binding to generate injection objects for gadget chain construction. Based on our empirical findings, we propose a novel gadget chain mining approach, \\emph{GCMiner}, which captures both explicit and implicit method calls to identify more gadget chains, and adopts an overriding-guided object generation approach to generate valid injection objects for fuzzing. The evaluation results show that emph{GCMiner} significantly outperforms the state-of-the-art techniques, and discovers 56 unique gadget chains that cannot be identified by the baseline approaches.","tags":["Java deserialization vulnerability","gadget chain","method overriding","exploit generation"],"title":"Improving Java Deserialization Gadget Chain Mining via Overriding-Guided Object Generation","type":"publication"},{"authors":null,"categories":null,"content":"Our accelerating build script error detection work has been accepted by ASE 2022.\nDetails of publications → ","date":1672876800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1672876800,"objectID":"cd746b89b3ed48d39f57cef24f5055ad","permalink":"https://s-cube-xmu.github.io/zh/post/virtualbuild2022/","publishdate":"2023-01-05T00:00:00Z","relpermalink":"/zh/post/virtualbuild2022/","section":"post","summary":"Our accelerating build script error detection work has been accepted by ASE 2022.\n","tags":null,"title":"Our accelerating build script error detection work has been accepted by ASE 2022","type":"post"},{"authors":null,"categories":null,"content":"Our database logical bugs detection work has been accepted by ASE 2022.\nDetails of publications → ","date":1672876800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1672876800,"objectID":"eaa1625650e159d5f8264d6755595a96","permalink":"https://s-cube-xmu.github.io/zh/post/smartpip2022/","publishdate":"2023-01-05T00:00:00Z","relpermalink":"/zh/post/smartpip2022/","section":"post","summary":"Our database logical bugs detection work has been accepted by ASE 2022.\n","tags":null,"title":"Our python ecosystem management work has been accepted by ASE 2022","type":"post"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1666569600,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://s-cube-xmu.github.io/zh/people/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/zh/people/","section":"","summary":"","tags":null,"title":"People","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1666569600,"objectID":"b0d61e5cbb7472bf320bf0ef2aaeb977","permalink":"https://s-cube-xmu.github.io/zh/tour/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/zh/tour/","section":"","summary":"","tags":null,"title":"Tour","type":"landing"},{"authors":["Rongxin Wu","Minglei Chen","Chengpeng Wang","Gang Fan","Jiguang Qiu","Charles Zhang"],"categories":null,"content":" ","date":166536e4,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":166536e4,"objectID":"bae1b149564cc0cdc2b18f12c336134c","permalink":"https://s-cube-xmu.github.io/zh/publication/virtualbuild/","publishdate":"2023-01-05T00:00:00Z","relpermalink":"/zh/publication/virtualbuild/","section":"publication","summary":"Build scripts play an important role in transforming the source code into executable artifacts. However, the development of build scripts is typically error-prone. As one kind of the most prevalent errors in build scripts, the dependency-related errors, including missing dependencies and redundant dependencies, draw the attention of many researchers. A variety of build dependency analysis techniques have been proposed to tackle them. Unfortunately, most of these techniques, even the state-of-the-art ones, suffer from efficiency issues due to the expensive cost of monitoring the complete build process to build dynamic dependencies. Especially for large-scale projects, such the cost would not be affordable. This work presents a new technique to accelerate the build dependency error detection by reducing the time cost of the build monitoring. Our key idea is to reduce the size of a program while still preserving the same dynamic dependencies as the original one. Building the reduced program does not generate a real software artifact, but it yields the same list of dependency errors and meanwhile speeds up the process. We implement the tool VirtualBuild and evaluate it on real-world projects. It is shown that it detects all the dependency errors found by existing tools at a low cost. Compared with the state-of-the-art technique, VirtualBuild  accelerates the build process by 8.74 times, and improves the efficiency of error detection by 6.13 times on average. Specifically, in the large-scale project LLVM that contains 5.67 MLoC, VirtualBuild  reduces the overall time from over four hours to 38.63  minutes.","tags":["Build script","Dependency error","Build accelerate"],"title":"Accelerating Build Dependency Error Detection via Virtual Build","type":"publication"},{"authors":["Chao Wang","Rongxin Wu","Haohao Song","Jiwu Shu","Guoqing Li"],"categories":null,"content":" ","date":166536e4,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":166536e4,"objectID":"93aeacaf3be87a4b6d10d7d7ab48b615","permalink":"https://s-cube-xmu.github.io/zh/publication/smartpip/","publishdate":"2023-01-05T00:00:00Z","relpermalink":"/zh/publication/smartpip/","section":"publication","summary":"As one of the representative software ecosystems, PyPI, together with the Python package management tool pip, greatly facilitates Python developers to automatically manage the reuse of third-party libraries, thus saving development time and cost. Despite its great success in practice, a recent empirical study revealed the risks of dependency conflict (DC) issues and then summarized the characteristics of DC issues. However, the dependency resolving strategy, which is the foundation of the prior study, has evolved to a new one, namely the backtracking strategy. To understand how the evolution of this dependency resolving strategy affects the prior findings, we conducted an empirical study to revisit the characteristics of DC issues under the new strategy. Our study revealed that, of the two previously discovered DC issue manifestation patterns, one has significantly changed (Pattern A), while the other remained the same (Pattern B). We also observed, the resolving strategy for the DC issues of Pattern A suffers from the efficiency issue, while the one for the DC issues of Pattern B would lead to a waste of time and space. Based on our findings, we propose a tool smartPip  to overcome the limitations of the resolving strategies. To resolve the DC issues of Pattern A, instead of iteratively verifying each candidate dependency library, we leverage a pre-built knowledge base of library dependencies to collect version constraints for concerned libraries, and then convert the version constraints into the SMT expressions for solving. To resolve the DC issues of Pattern B, we improve the existing virtual environment solution to reuse the local libraries as far as possible. Finally, we evaluated smartPip  in three benchmark datasets of open source projects. The results showed that, smartPip  can outperform the existing Python package management tools including pip with the new strategy and Conda in resolving DC issues of Pattern A, and achieve 1.19X - 1.60X speedups over the best baseline approach. Compared with the built-in Python virtual environment (venv), smartPip  reduced 34.55% - 80.26% of storage space and achieved up to 2.26X - 6.53X speedups in resolving the DC issues of Pattern B.","tags":["Python","Dependency conflict","Dependency resolving"],"title":"smartPip: A Smart Approach to Resolving Python Dependency Conflict Issues","type":"publication"},{"authors":["Ying Wang","Rongxin Wu","Chao Wang","Ming Wen","Yepang Liu","Shing-Chi Cheung","Hai Yu","Chang Xu","Zhiliang Zhu"],"categories":null,"content":" ","date":1656633600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1656633600,"objectID":"dd98a697625e938c0350b60835749586","permalink":"https://s-cube-xmu.github.io/zh/publication/will-dependency-conflicts-affect-my-programs-semantics-2021/","publishdate":"2021-02-08T00:00:00Z","relpermalink":"/zh/publication/will-dependency-conflicts-affect-my-programs-semantics-2021/","section":"publication","summary":"Java projects are often built on top of various third-party libraries. If multiple versions of a library exist on the classpath, JVM will only load one version and shadow the others, which we refer to as dependency conflicts . This would give rise to semantic conflict (SC) issues, if the library APIs referenced by a project have identical method signatures but inconsistent semantics across the loaded and shadowed versions of libraries. SC issues are difficult for developers to diagnose in practice, since understanding them typically requires domain knowledge. Although adapting the existing test generation technique for dependency conflict issues, Riddle , to detect SC issues is feasible, its effectiveness is greatly compromised. This is mainly because Riddle randomly generates test inputs, while the SC issues typically require specific arguments in the tests to be exposed. To address that, we conducted an empirical study of 316 real SC issues to understand the characteristics of such specific arguments in the test cases that can capture the SC issues. Inspired by our empirical findings, we propose an automated testing technique Sensor , which synthesizes test cases using ingredients from the project under test to trigger inconsistent behaviors of the APIs with the same signatures in conflicting library versions. Our evaluation results show that Sensor is effective and useful: it achieved a Precision of 0.898 and a Recall of 0.725 on open-source projects and a Precision of 0.821 on industrial projects; it detected 306 semantic conflict issues in 50 projects, 70.4 percent of which had been confirmed as real bugs, and 84.2 percent of the confirmed issues have been fixed quickly.","tags":["Third-party libraries","test generation","empirical study"],"title":"Will Dependency Conflicts Affect My Program's Semantics?","type":"publication"},{"authors":["Sicong Cao","Xiaobing Sun","Lili Bo","Rongxin Wu","Bin Li","Chuanqi Tao"],"categories":null,"content":" ","date":1653436800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1653436800,"objectID":"838488c656f053bead57465cff8f0023","permalink":"https://s-cube-xmu.github.io/zh/publication/mvd-2022/","publishdate":"2022-06-20T00:00:00Z","relpermalink":"/zh/publication/mvd-2022/","section":"publication","summary":"Memory-related vulnerabilities constitute severe threats to the security of modern software. Despite the success of deep learning-based approaches to generic vulnerability detection, they are still limited by the underutilization of flow information when applied for detecting memory-related vulnerabilities, leading to high false positives. In this paper, we propose MVD, a statement-level Memory-related Vulnerability Detection approach based on flow-sensitive graph neural networks (FS-GNN). FS-GNN is employed to jointly embed both unstructured information (i.e., source code) and structured information (i.e., control- and data-flow) to capture implicit memory-related vulnerability patterns. We evaluate MVD on the dataset which contains 4,353 real-world memory-related vulnerabilities, and compare our approach with three state-of-the-art deep learning-based approaches as well as five popular static analysis-based memory detectors. The experiment results show that MVD achieves better detection accuracy, outperforming both state-of-the-art DL-based and static analysis-based approaches. Furthermore, MVD makes a great trade-off between accuracy and efficiency.","tags":["Memory-Related Vulnerability","Vulnerability Detection","Graph Neural Networks","Flow Analysis"],"title":"MVD: memory-related vulnerability detection based on flow-sensitive graph neural networks","type":"publication"},{"authors":["Heqing Huang","Yiyuan Guo","Qingkai Shi","Peisen Yao","Rongxin Wu","Charles Zhang"],"categories":null,"content":" ","date":1653177600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1653177600,"objectID":"fad12e4a04d112c86dcfba429dae4c75","permalink":"https://s-cube-xmu.github.io/zh/publication/beacon-2022/","publishdate":"2022-07-27T00:00:00Z","relpermalink":"/zh/publication/beacon-2022/","section":"publication","summary":"Unlike coverage-based fuzzing that gives equal attention to every part of a code, directed fuzzing aims to direct a fuzzer to a specific target in the code, e.g., the code with potential vulnerabilities. Despite much progress, we observe that existing directed fuzzers are still not efficient as they often symbolically or concretely execute a lot of program paths that cannot reach the target code. They thus waste a lot of computational resources. This paper presents BEACON, which can effectively direct a grey-box fuzzer in the sea of paths in a provable manner. That is, assisted by a lightweight static analysis that computes abstracted preconditions for reaching the target, we can prune 82.94% of the executing paths at runtime with negligible analysis overhead (\u003c5h) but with the guarantee that the pruned paths must be spurious with respect to the target. We have implemented our approach, BEACON, and compared it to five state-of-the-art (directed) fuzzers in the application scenario of vulnerability reproduction. The evaluation results demonstrate that BEACON is 11.50x faster on average than existing directed grey-box fuzzers and it can also improve the speed of the conventional coverage-guided fuzzers, AFL, AFL++, and Mopt, to reproduce specific bugs with 6.31x, 11.86x, and 10.92x speedup, respectively. More interestingly, when used to test the vulnerability patches, BEACON found 14 incomplete fixes of existing CVE-identified vulnerabilities and 8 new bugs while 10 of them are exploitable with new CVE ids assigned.","tags":["Directed fuzzing","precondition inference","program transformation"],"title":"BEACON: Directed Grey-Box Fuzzing with Provable Path Pruning","type":"publication"},{"authors":["Yixing Luo","Xiao-Yi Zhang","Paolo Arcaini","Zhi Jin","Haiyan Zhao","Fuyuki Ishikawa","Rongxin Wu","Tao Xie"],"categories":null,"content":" ","date":1636934400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1636934400,"objectID":"7d6cf6a42844292e2306c62646983e0a","permalink":"https://s-cube-xmu.github.io/zh/publication/targetingrequirementsviolations-2021/","publishdate":"2021-11-15T00:00:00Z","relpermalink":"/zh/publication/targetingrequirementsviolations-2021/","section":"publication","summary":"Autonomous Driving Systems (ADSs) are complex systems that must satisfy multiple requirements such as safety, compliance to traffic rules, and comfortableness. However, satisfying all these requirements may not always be possible due to emerging environmental conditions. Therefore, the ADSs may have to make trade-offs among multiple requirements during the ongoing operation, resulting in one or more requirements violations. For ADS engineers, it is highly important to know which combinations of requirements violations may occur, as different combinations can expose different types of failures. However, there is currently no testing approach that can generate scenarios to expose different combinations of requirements violations. To address this issue, in this paper, we introduce the notion of requirements violation pattern to characterize a specific combination of requirements violations. Based on this notion, we propose a testing approach named EMOOD that can effectively generate test scenarios to expose as many requirements violation patterns as possible. EMOOD uses a prioritization technique to sort all possible patterns to search for, from the most to the least critical ones. Then, EMOOD iteratively includes an evolutionary many-objective optimization algorithm to find different combinations of requirements violations. In each iteration, the targeted pattern is determined by a dynamic prioritization technique to give preferences to those patterns with higher criticality and higher likelihood to occur. We apply EMOOD to an industrial ADS under two common traffic situations. Evaluation results show that EMOOD outperforms three baseline approaches in generating test scenarios by discovering more requirements violation patterns.","tags":["Heuristic algorithms","Safety","Complex systems","Autonomous vehicles","Optimization","Testing","Software engineering"],"title":"Targeting Requirements Violations of Autonomous Driving Systems by Dynamic Evolutionary Search","type":"publication"},{"authors":["Wensheng Tang","Yikun Hu","Gang Fan","Peisen Yao","Rongxin Wu","Guangyuan Bai","Pengcheng Wang","Charles Zhang"],"categories":null,"content":" ","date":1636934400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1636934400,"objectID":"3bdecd6ec42fd844c1a088e389f2012c","permalink":"https://s-cube-xmu.github.io/zh/publication/transcode-2021/","publishdate":"2021-11-15T00:00:00Z","relpermalink":"/zh/publication/transcode-2021/","section":"publication","summary":"Status code mappings reveal state shifts of a program, mapping one status code to another. Due to careless programming or the lack of the system-wide knowledge of a whole program, developers can make incorrect mappings. Such errors are widely spread across modern software, some of which have even become critical vulnerabilities. Unfortunately, existing solutions merely focus on single status code values, while never considering the relationships, that is, mappings, among them. Therefore, it is imperative to propose an effective method to detect status code mapping errors.In this paper, we propose Transcode to detect potential status code mapping errors. It firstly conducts value flow analysis to efficiently and precisely collect candidate status code values, that is, the integer values, which are checked by following conditional comparisons. Then, it aggregates the correlated status codes according to whether they are propagated with the same variable. Finally, Transcode extracts mappings based on control dependencies and reports the mapping error if one status code is mapped to two others of the same kind. We have implemented Transcode as a prototype system, and evaluated it with 5 real-world software projects, each of which possesses in the order of a million lines of code. The experimental results show that Transcode is capable of handling large-scale systems in both a precise and efficient manner. Furthermore, it has discovered 59 new errors in the tested projects, among which 13 have been fixed by the community. We also deploy Transcode in WeChat, a widely-used instant messaging service, and have succeeded in finding real mapping errors in the industrial settings.","tags":["Codes","Social networking (online)","Aggregates","Prototypes","Instant messaging","Programming","Software"],"title":"Transcode: Detecting Status Code Mapping Errors in Large-Scale Systems","type":"publication"},{"authors":["Ming Wen","Junjie Chen","Yongqiang Tian","Rongxin Wu*","Dan Hao","Shi Han and Shing-Chi Cheung"],"categories":null,"content":" ","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1635724800,"objectID":"1c9a404f30ee02f7030067914a53b3f3","permalink":"https://s-cube-xmu.github.io/zh/publication/historical-spectrum-based-fault-localization-2021/","publishdate":"2019-10-17T00:00:00Z","relpermalink":"/zh/publication/historical-spectrum-based-fault-localization-2021/","section":"publication","summary":"Spectrum-based fault localization (SBFL) techniques are widely studied and have been evaluated to be effective in locating faults. Recent studies also showed that developers from industry value automated SBFL techniques. However, their effectiveness is still limited by two main reasons. First, the test coverage information leveraged to construct the spectrum does not reflect the root cause directly. Second, SBFL suffers from the tie issue so that the buggy code entities can not be well differentiated from non-buggy ones. To address these challenges, we propose to leverage the information of version histories in fault localization based on the following two intuitions. First, version histories record how bugs are introduced to software projects and this information reflects the root cause of bugs directly. Second, the evolution histories of code can help differentiate those suspicious code entities ranked in tie by SBFL. Our intuitions are also inspired by the observations on debugging practices from large open source projects and industry. Based on the intuitions, we propose a novel technique HSFL (historical spectrum based fault localization). Specifically, HSFL identifies bug-inducing commits from the version history in the first step. It then constructs historical spectrum (denoted as Histrum) based on bug-inducing commits, which is another dimension of spectrum orthogonal to the coverage based spectrum used in SBFL. HSFL finally ranks the suspicious code elements based on our proposed Histrum and the conventional spectrum. HSFL outperforms the state-of-the-art SBFL techniques significantly on the Defects4J benchmark. Specifically, it locates and ranks the buggy statement at Top-1 for 77.8 percent more bugs as compared with SBFL, and 33.9 percent more bugs at Top-5. Besides, for the metrics MAP and MRR, HSFL achieves an average improvement of 28.3 and 40.8 percent over all bugs, respectively. Moreover, HSFL can also outperform other six families of fault localization techniques, and our proposed Histrum model can be integrated with different families of techniques and boost their performance.","tags":["Fault localization","version histories","bug-inducing commits"],"title":"Historical Spectrum based Fault Localization","type":"publication"},{"authors":["Peisen Yao","Heqing Huang","Wensheng Tang","Qingkai Shi","Rongxin Wu","Charles Zhang"],"categories":null,"content":" ","date":1631923200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1631923200,"objectID":"d7c1a44ee19d91d9bc064865628dc25e","permalink":"https://s-cube-xmu.github.io/zh/publication/sae-2021/","publishdate":"2021-09-18T00:00:00Z","relpermalink":"/zh/publication/sae-2021/","section":"publication","summary":"Ensuring the equality of SMT solvers is critical due to its broad spectrum of applications in academia and industry, such as symbolic execution and program verification. Existing approaches to testing SMT solvers are either too costly or find difficulties generalizing to different solvers and theories, due to the test oracle problem. To complement existing approaches and overcome their weaknesses, this paper introduces skeletal approximation enumeration (SAE), a novel lightweight and general testing technique for all first-order theories. To demonstrate its practical utility, we have applied the SAE technique to test Z3 and CVC4, two comprehensively tested, state-of-the-art SMT solvers. By the time of writing, our approach had found 71 confirmed bugs in Z3 and CVC4,55 of which had already been fixed.","tags":["SMT solver testing","Metamorphic testing","Mutation-based-testing"],"title":"Skeletal Approximation Enumeration for SMT Solver Testing","type":"publication"},{"authors":["Peisen Yao","Heqing Huang","Wensheng Tang","Qingkai Shi","Rongxin Wu","Charles Zhang"],"categories":null,"content":" ","date":1625961600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1625961600,"objectID":"dbc6e1f4ea9415926927e6ed8a6769ad","permalink":"https://s-cube-xmu.github.io/zh/publication/fuzzingsmtsolver-2021/","publishdate":"2021-07-11T00:00:00Z","relpermalink":"/zh/publication/fuzzingsmtsolver-2021/","section":"publication","summary":"Satisfiability Modulo Theories (SMT) solvers serve as the core engine of many techniques, such as symbolic execution. Therefore, ensuring the robustness and correctness of SMT solvers is critical. While fuzzing is an efficient and effective method for validating the quality of SMT solvers, we observe that prior fuzzing work only focused on generating various first-order formulas as the inputs but neglected the algorithmic configuration space of an SMT solver, which leads to under-reporting many deeply-hidden bugs. In this paper, we present Falcon, a fuzzing technique that explores both the formula space and the configuration space. Combining the two spaces significantly enlarges the search space and makes it challenging to detect bugs efficiently. We solve this problem by utilizing the correlations between the two spaces to reduce the search space, and introducing an adaptive mutation strategy to boost the search efficiency. During six months of extensive testing, Falcon finds 518 confirmed bugs in CVC4 and Z3, two state-of-the-art SMT solvers, 469 of which have already been fixed. Compared to two state-of-the-art fuzzers, Falcon detects 38 and 44 more bugs and improves the coverage by a large margin in 24 hours of testing.","tags":["Fuzz testing","SMT solvers"],"title":"Fuzzing SMT Solvers via Two-Dimensional Input Space Exploration","type":"publication"},{"authors":["Qingkai Shi","Peisen Yao","Rongxin Wu","Charles Zhang"],"categories":null,"content":" ","date":1623974400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1623974400,"objectID":"4700eec5adf45f523085bafb90049dac","permalink":"https://s-cube-xmu.github.io/zh/publication/pathsensitivesparseanalyse-2021/","publishdate":"2021-06-18T00:00:00Z","relpermalink":"/zh/publication/pathsensitivesparseanalyse-2021/","section":"publication","summary":"Sparse program analysis is fast as it propagates data flow facts via data dependence, skipping unnecessary control flows. However, when path-sensitively checking millions of lines of code, it is still prohibitively expensive because a huge number of path conditions have to be computed and solved via an SMT solver. This paper presents Fusion, a fused approach to inter-procedurally path-sensitive sparse analysis. In Fusion, the SMT solver does not work as a standalone tool on path conditions but directly on the program together with the sparse analysis. Such a fused design allows us to determine the path feasibility without explicitly computing path conditions, not only saving the cost of computing path conditions but also providing an opportunity to enhance the SMT solving algorithm. To the best of our knowledge, Fusion, for the first time, enables whole program bug detection on millions of lines of code in a common personal computer, with the precision of inter-procedural path-sensitivity. Compared to two state-of-the-art tools, Fusion is 10× faster but consumes only 10% of memory on average. Fusion has detected over a hundred bugs in mature open-source software, some of which have even been assigned CVE identifiers due to their security impact.","tags":["Sparse analyse","Path sensitivity","Program dependence graph","SMT solving"],"title":"Path-Sensitive Sparse Analysis without Path Conditions","type":"publication"},{"authors":["Seonah Lee","Rongxin Wu","Shing-Chi Cheung","Sungwon Kang"],"categories":null,"content":" ","date":1618012800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1618012800,"objectID":"daa3c9e1633ba3373ac9288781675a83","permalink":"https://s-cube-xmu.github.io/zh/publication/automatic-detection-and-update-suggestion-for-outdated-api-names-in-documentation-2019/","publishdate":"2019-02-24T00:00:00Z","relpermalink":"/zh/publication/automatic-detection-and-update-suggestion-for-outdated-api-names-in-documentation-2019/","section":"publication","summary":"Application programming interfaces (APIs) continually evolve to meet ever-changing user needs, and documentation provides an authoritative reference for their usage. However, API documentation is commonly outdated because nearly all of the associated updates are performed manually. Such outdated documentation, especially with regard to API names, causes major software development issues. In this paper, we propose a method for automatically updating outdated API names in API documentation. Our insight is that API updates in documentation can be derived from API implementation changes between code revisions. To evaluate the proposed method, we applied it to four open source projects. Our evaluation results show that our method, FreshDoc, detects outdated API names in API documentation with 48 percent higher accuracy than the existing state-of-the-art methods do. Moreover, when we checked the updates suggested by FreshDoc against the developers' manual updates in the revised documentation, FreshDoc detected 82 percent of the outdated names. When we reported 40 outdated API names found by FreshDoc via issue tracking systems, developers accepted 75 percent of the suggestions. These evaluation results indicate that FreshDoc can be used as a practical method for the detection and updating of API names in the associated documentation.","tags":["Application programming interfaces","documentation","history","software maintenance"],"title":"Automatic Detection and Update Suggestion for Outdated API Names in Documentation","type":"publication"},{"authors":["Gang Fan","Chengpeng Wang","Rongxin Wu","Qingkai Shi","Charles Zhang"],"categories":null,"content":" ","date":1595030400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1595030400,"objectID":"e5822b6611987d4ccadfb6985ddfd219","permalink":"https://s-cube-xmu.github.io/zh/publication/escapingdependencyhell-2020/","publishdate":"2020-07-18T00:00:00Z","relpermalink":"/zh/publication/escapingdependencyhell-2020/","section":"publication","summary":"Modern software projects rely on build systems and build scripts to assemble executable artifacts correctly and efficiently. However, developing build scripts is error-prone. Dependency-related errors in build scripts, mainly including missing dependencies and redundant dependencies, are common in various kinds of software projects. These errors lead to build failures, incorrect build results or poor performance in incremental or parallel builds. To detect such errors, various techniques are proposed and suffer from low efficiency and high false positive problems, due to the deficiency of the underlying dependency graphs. In this work, we design a new dependency graph, the unified dependency graph (UDG), which leverages both static and dynamic information to uniformly encode the declared and actual dependencies between build targets and files. The construction of UDG facilitates the efficient and precise detection of dependency errors via simple graph traversals. We implement the proposed approach as a tool, VeriBuild, and evaluate it on forty-two well-maintained open-source projects. The experimental results show that, without losing precision, VeriBuild incurs 58.2% less overhead than the state-of-the-art approach. By the time of writing, 398 detected dependency issues have been confirmed by the developers.","tags":["Build maintenance","Build tools","Dependency verification"],"title":"Escaping Dependency Hell: Finding Build Dependency Errors with the Unified Dependency Graph","type":"publication"},{"authors":["Qingkai Shi","Rongxin Wu","Gang Fan","Charles Zhang"],"categories":null,"content":" ","date":1593216e3,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1593216e3,"objectID":"499c06b7f32cb5f5f1746aad2cd88f12","permalink":"https://s-cube-xmu.github.io/zh/publication/conquering-2020/","publishdate":"2020-06-27T00:00:00Z","relpermalink":"/zh/publication/conquering-2020/","section":"publication","summary":"Modern static analyzers often need to simultaneously check a few dozen or even hundreds of value-flow properties, causing serious scalability issues when high precision is required. A major factor to this deficiency, as we observe, is that the core static analysis engine is oblivious of the mutual synergy among the properties being checked, thus inevitably losing many optimization opportunities. Our work is to leverage the inter-property awareness and to capture redundancies and inconsistencies when many properties are considered at the same time. We have evaluated our approach by checking twenty value-flow properties in standard benchmark programs and ten real-world software systems. The results demonstrate that our approach is more than 8× faster than existing ones but consumes only 1/7 of the memory. Such substantial improvement in analysis efficiency is not achieved by sacrificing the effectiveness: at the time of writing, thirty-nine bugs found by our approach have been fixed by developers and four of them have been assigned CVE IDs due to their security impact.","tags":["Value-flow analysis","Static bug finding","Demand-driven analysis","Compositional program analysis"],"title":"Conquering the Extensional Scalability Problem for Value-Flow Analysis Frameworks","type":"publication"},{"authors":["Heqing Huang","Peisen Yao","Rongxin Wu","Qingkai Shi","Charles Zhang"],"categories":null,"content":" ","date":158976e4,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":158976e4,"objectID":"c83b5d5e4f49f4f8a1a5c1d60702b0ed","permalink":"https://s-cube-xmu.github.io/zh/publication/pangolin-2020/","publishdate":"2020-05-18T00:00:00Z","relpermalink":"/zh/publication/pangolin-2020/","section":"publication","summary":"Hybrid fuzzing, which combines the merits of both fuzzing and concolic execution, has become one of the most important trends in coverage-guided fuzzing techniques. Despite the tremendous research on hybrid fuzzers, we observe that existing techniques are still inefficient. One important reason is that these techniques, which we refer to as non-incremental fuzzers, cache and reuse few computation results and, thus, lose many optimization opportunities. To be incremental, we propose \"polyhedral path abstraction\", which preserves the exploration state in the concolic execution stage and allows more effective mutation and constraint solving over existing techniques. We have implemented our idea as a tool, namely Pangolin, and evaluated it using LAVA-M as well as nine real-world programs. The evaluation results showed that Pangolin outperforms the state-of-the-art fuzzing techniques with the improvement of coverage rate ranging from 10% to 30%. Moreover, Pangolin found 400 more bugs in LAVA-M and discovered 41 unseen bugs with 8 of them assigned with the CVE IDs.","tags":["Fuzzing","Constraint solving","Program analysis","Sampling"],"title":"Pangolin: Incremental Hybrid Fuzzing with Polyhedral Path Abstraction","type":"publication"},{"authors":["Ming Wen","Rongxin Wu","Yepang Liu","Yongqiang Tian","Xuan Xie","Shing-Chi Cheung","Zhendong Su"],"categories":null,"content":" ","date":1566777600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1566777600,"objectID":"beb4e0129879a3b488c6bd41e9f04088","permalink":"https://s-cube-xmu.github.io/zh/publication/exploring-and-exploiting-2019/","publishdate":"2019-08-26T00:00:00Z","relpermalink":"/zh/publication/exploring-and-exploiting-2019/","section":"publication","summary":"Bug-inducing commits provide important information to understand when and how bugs were introduced. Therefore, they have been extensively investigated by existing studies and frequently leveraged to facilitate bug fixings in industrial practices. Due to the importance of bug-inducing commits in software debugging, we are motivated to conduct the first systematic empirical study to explore the correlations between bug-inducing and bug-fixing commits in terms of code elements and modifications. To facilitate the study, we collected the inducing and fixing commits for 333 bugs from seven large open-source projects. The empirical findings reveal important and significant correlations between a bug's inducing and fixing commits. We further exploit the usefulness of such correlation findings from two aspects. First, they explain why the SZZ algorithm, the most widely-adopted approach to collecting bug-inducing commits, is imprecise. In view of SZZ's imprecision, we revisited the findings of previous studies based on SZZ, and found that 8 out of 10 previous findings are significantly affected by SZZ's imprecision. Second, they shed lights on the design of automated debugging techniques. For demonstration, we designed approaches that exploit the correlations with respect to statements and change actions. Our experiments on Defects4J show that our approaches can boost the performance of fault localization significantly and also advance existing APR techniques.","tags":["Empirical study","bug-inducing commits","fault localization and repair"],"title":"Exploring and Exploiting the Correlations between Bug-Inducing and Bug-Fixing Commits","type":"publication"},{"authors":["Ying Wang","Ming Wen","Rongxin Wu","Zhenwei Liu","Shin Hwei Tan","Zhiliang Zhu","Hai Yu","Shing-Chi Cheung"],"categories":null,"content":" ","date":1558742400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1558742400,"objectID":"59149aa4d6b640f9fe445ac61acdfb34","permalink":"https://s-cube-xmu.github.io/zh/publication/could-i-have-2019/","publishdate":"2019-05-25T00:00:00Z","relpermalink":"/zh/publication/could-i-have-2019/","section":"publication","summary":"Intensive use of libraries in Java projects brings potential risk of dependency conflicts, which occur when a project directly or indirectly depends on multiple versions of the same library or class. When this happens, JVM loads one version and shadows the others. Runtime exceptions can occur when methods in the shadowed versions are referenced. Although project management tools such as Maven are able to give warnings of potential dependency conflicts when a project is built, developers often ask for crashing stack traces before examining these warnings. It motivates us to develop Riddle, an automated approach that generates tests and collects crashing stack traces for projects subject to risk of dependency conflicts. Riddle, built on top of Asm and Evosuite, combines condition mutation, search strategies and condition restoration. We applied Riddle on 19 real-world Java projects with duplicate libraries or classes. We reported 20 identified dependency conflicts including their induced crashing stack traces and the details of generated tests. Among them, 15 conflicts were confirmed by developers as real issues, and 10 were readily fixed. The evaluation results demonstrate the effectiveness and usefulness of Riddle.","tags":["Test generation","Mutation","Third-party library"],"title":"Could I Have a Stack Trace to Examine the Dependency Conflict Issue?","type":"publication"},{"authors":["Ming Wen","Yepang Liu","Rongxin Wu","Xuan Xie","Shing-Chi Cheung","Zhendong Su"],"categories":null,"content":" ","date":1558742400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1558742400,"objectID":"5423021c028dbb2fb496c30564aac63c","permalink":"https://s-cube-xmu.github.io/zh/publication/exposing-library-2019/","publishdate":"2019-05-25T00:00:00Z","relpermalink":"/zh/publication/exposing-library-2019/","section":"publication","summary":"Misuses of library APIs are pervasive and often lead to software crashes and vulnerability issues. Various static analysis tools have been proposed to detect library API misuses. They often involve mining frequent patterns from a large number of correct API usage examples, which can be hard to obtain in practice. They also suffer from low precision due to an over-simplified assumption that a deviation from frequent usage patterns indicates a misuse. We make two observations on the discovery of API misuse patterns. First, API misuses can be represented as mutants of the corresponding correct usages. Second, whether a mutant will introduce a misuse can be validated via executing it against a test suite and analyzing the execution information. Based on these observations, we propose MutApi, the first approach to discovering API misuse patterns via mutation analysis. To effectively mimic API misuses based on correct usages, we first design eight effective mutation operators inspired by the common characteristics of API misuses. MutApi generates mutants by applying these mutation operators on a set of client projects and collects mutant-killing tests as well as the associated stack traces. Misuse patterns are discovered from the killed mutants that are prioritized according to their likelihood of causing API misuses based on the collected information. We applied MutApi on 16 client projects with respect to 73 popular Java APIs. The results show that MutApi is able to discover substantial API misuse patterns with a high precision of 0.78. It also achieves a recall of 0.49 on the MuBench benchmark, which outperforms the state-of-the-art techniques.","tags":["Mutation analysis","Library API misuses"],"title":"Exposing Library API Misuses Via Mutation Analysis","type":"publication"},{"authors":["Gang Fan","Rongxin Wu","Qingkai Shi","Xiao Xiao","Jinguo Zhou","Charles Zhang"],"categories":null,"content":" ","date":1558742400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1558742400,"objectID":"418cf8a8890b94b2907330cea7ef976e","permalink":"https://s-cube-xmu.github.io/zh/publication/smoke-2019/","publishdate":"2019-05-25T00:00:00Z","relpermalink":"/zh/publication/smoke-2019/","section":"publication","summary":"Detecting memory leak at industrial scale is still not well addressed, in spite of the tremendous effort from both industry and academia in the past decades. Existing work suffers from an unresolved paradox - a highly precise analysis limits its scalability and an imprecise one seriously hurts its precision or recall. In this work, we present SMOKE, a staged approach to resolve this paradox. In the first stage, instead of using a uniform precise analysis for all paths, we use a scalable but imprecise analysis to compute a succinct set of candidate memory leak paths. In the second stage, we leverage a more precise analysis to verify the feasibility of those candidates. The first stage is scalable, due to the design of a new sparse program representation, the use-flow graph (UFG), that models the problem as a polynomial-time state analysis. The second stage analysis is both precise and efficient, due to the smaller number of candidates and the design of a dedicated constraint solver. Experimental results show that SMOKE can finish checking industrial-sized projects, up to 8MLoC, in forty minutes with an average false positive rate of 24.4%. Besides, SMOKE is significantly faster than the state-of-the-art research techniques as well as the industrial tools, with the speedup ranging from 5.2X to 22.8X. In the twenty-nine mature and extensively checked benchmark projects, SMOKE has discovered thirty previously unknown memory leaks which were confirmed by developers, and one even assigned a CVE ID.","tags":["Memory leak","Static bug finding","use-flow graph","value-flow graph"],"title":"SMOKE: Scalable Path-Sensitive Memory Leak Detection for Millions of Lines of Code","type":"publication"},{"authors":["Ming Wen","Rongxin Wu*","Shing-Chi Cheung"],"categories":null,"content":" ","date":1539648e3,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1539648e3,"objectID":"ef381b88985a3a2130abd57855a727b0","permalink":"https://s-cube-xmu.github.io/zh/publication/how-well-do-change-sequences-predict-defects-sequence-learning-from-software-changes-2020/","publishdate":"2020-11-01T00:00:00Z","relpermalink":"/zh/publication/how-well-do-change-sequences-predict-defects-sequence-learning-from-software-changes-2020/","section":"publication","summary":"Software defect prediction, which aims to identify defective modules, can assist developers in finding bugs and prioritizing limited quality assurance resources. Various features to build defect prediction models have been proposed and evaluated. Among them, process metrics are one important category. Yet, existing process metrics are mainly encoded manually from change histories and ignore the sequential information arising from the changes during software evolution. Are the change sequences derived from such information useful to characterize buggy program modules? How can we leverage such sequences to build good defect prediction models? Unlike traditional process metrics used for existing defect prediction models, change sequences are mostly vectors of variable length. This makes it difficult to apply such sequences directly in prediction models that are driven by conventional classifiers. To resolve this challenge, we utilize Recurrent Neural Network (RNN), which is a deep learning technique, to encode features from sequence data automatically. In this paper, we propose a novel approach called Fences, which extracts six types of change sequences covering different aspects of software changes via fine-grained change analysis. It approaches defects prediction by mapping it to a sequence labeling problem solvable by RNN. Our evaluations on 10 open source projects show that Fences can predict defects with high performance. In particular, our approach achieves an average F-measure of 0.657, which improves the prediction models built on traditional metrics significantly. The improvements vary from 31.6 to 46.8 percent on average. In terms of AUC, Fences achieves an average value of 0.892, and the improvements over baselines vary from 4.2 to 16.1 percent. Fences also outperforms the state-of-the-art technique which learns semantic features automatically from static code via deep learning.","tags":["Defect prediction","process metrics","sequence learning"],"title":"How Well Do Change Sequences Predict Defects? Sequence Learning from Software Changes","type":"publication"},{"authors":["Qingkai Shi","Xiao Xiao","Rongxin Wu","Jinguo Zhou","Gang Fan","Charles Zhang"],"categories":null,"content":" ","date":152928e4,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":152928e4,"objectID":"797bce00025aeaabbc3cc5c25c174cb9","permalink":"https://s-cube-xmu.github.io/zh/publication/pinpoint-2018/","publishdate":"2018-06-18T00:00:00Z","relpermalink":"/zh/publication/pinpoint-2018/","section":"publication","summary":"When dealing with millions of lines of code, we still cannot have the cake and eat it: sparse value-flow analysis is powerful in checking source-sink problems, but existing work cannot escape from the “pointer trap” – a precise points-to analysis limits its scalability and an imprecise one seriously undermines its precision. We present Pinpoint, a holistic approach that decomposes the cost of high-precision points-to analysis by precisely discovering local data dependence and delaying the expensive inter-procedural analysis through memorization. Such memorization enables the on-demand slicing of only the necessary inter-procedural data dependence and path feasibility queries, which are then solved by a costly SMT solver. Experiments show that Pinpoint can check programs such as MySQL (around 2 million lines of code) within 1.5 hours. The overall false positive rate is also very low (14.3% - 23.6%). Pinpoint has discovered over forty real bugs in mature and extensively checked open source systems. And the implementation of Pinpoint and all experimental results are freely available.","tags":["Sparse program analysis","path-sensitive analysis","error detection"],"title":"Pinpoint: Fast and Precise Sparse Value Flow Analysis for Million Lines of Code","type":"publication"},{"authors":["Rongxin Wu","Ming Wen","Shing-Chi Cheung","Hongyu Zhang"],"categories":null,"content":" ","date":1527984e3,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1527984e3,"objectID":"d2f7f681e25ce7067533476956079365","permalink":"https://s-cube-xmu.github.io/zh/publication/changelocator-2018/","publishdate":"2018-06-03T00:00:00Z","relpermalink":"/zh/publication/changelocator-2018/","section":"publication","summary":"Software crashes are severe manifestations of software bugs. Debugging crashing bugs is tedious and time-consuming. Understanding software changes that induce a crashing bug can provide useful contextual information for bug fixing and is highly demanded by developers. Locating the bug inducing changes is also useful for automatic program repair, since it narrows down the root causes and reduces the search space of bug fix location. However, currently there are no systematic studies on locating the software changes to a source code repository that induce a crashing bug reflected by a bucket of crash reports. To tackle this problem, we first conducted an empirical study on characterizing the bug inducing changes for crashing bugs (denoted as crashinducing changes). We also propose ChangeLocator, a method to automatically locate crash-inducing changes for a given bucket of crash reports. We base our approach on a learning model that uses features originated from our empirical study and train the model using the data from the historical fixed crashes. We evaluated ChangeLocator with six release versions of Netbeans project. The results show that it can locate the crash-inducing changes for 44.7%, 68.5%, and 74.5% of the bugs by examining only top 1, 5 and 10 changes in the recommended list, respectively. It significantly outperforms the existing state-of-the-art approach.","tags":["crash-inducing change","software crash","crash stack","bug localization"],"title":"ChangeLocator: Locate Crash-Inducing Changes Based on Crash Reports","type":"publication"},{"authors":["Ming Wen","Junjie Chen","Rongxin Wu","Dan Hao","Shing-Chi Cheung"],"categories":null,"content":" ","date":1527379200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1527379200,"objectID":"5f19cbe87c8a3b53389269dfe6459ff4","permalink":"https://s-cube-xmu.github.io/zh/publication/context-aware-patch-2018/","publishdate":"2018-05-27T00:00:00Z","relpermalink":"/zh/publication/context-aware-patch-2018/","section":"publication","summary":"The effectiveness of search-based automated program repair is limited in the number of correct patches that can be successfully generated. There are two causes of such limitation. First, the search space does not contain the correct patch. Second, the search space is huge and therefore the correct patch cannot be generated (i.e., correct patches are either generated after incorrect plausible ones or not generated within the time budget). To increase the likelihood of including the correct patches in the search space, we propose to work at a fine granularity in terms of AST nodes. This, however, will further enlarge the search space, increasing the challenge to find the correct patches. We address the challenge by devising a strategy to prioritize the candidate patches based on their likelihood of being correct. Specifically, we study the use of AST nodes' context information to estimate the likelihood. In this paper, we propose CapGen, a context-aware patch generation technique. The novelty which allows CapGen to produce more correct patches lies in three aspects (1) The fine-granularity design enables it to find more correct fixing ingredients; (2) The context-aware prioritization of mutation operators enables it to constrain the search space; (3) Three context-aware models enable it to rank correct patches at high positions before incorrect plausible ones. We evaluate CapGen on Defects4J and compare it with the state-of-the-art program repair techniques. Our evaluation shows that CapGen outperforms and complements existing techniques. CapGen achieves a high precision of 84.00% and can prioritize the correct patches before 98.78% of the incorrect plausible ones.","tags":["Automated Program Repair","Patch Prioritization"],"title":"Context-Aware Patch Generation for Better Automated Program Repair","type":"publication"},{"authors":["Ming Ming","Rongxin Wu","Shing-Chi Cheung"],"categories":null,"content":" ","date":1472860800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1472860800,"objectID":"d3756e56bf68a37b49e4010ab6646ebe","permalink":"https://s-cube-xmu.github.io/zh/publication/locus-2016/","publishdate":"2016-09-03T00:00:00Z","relpermalink":"/zh/publication/locus-2016/","section":"publication","summary":"Various information retrieval (IR) based techniques have been proposed recently to locate bugs automatically at the file level. However, their usefulness is often compromised by the coarse granularity of files and the lack of contextual information. To address this, we propose to locate bugs using software changes, which offer finer granularity than files and provide important contextual clues for bug-fixing. We observe that bug inducing changes can facilitate the bug fixing process. For example, it helps triage the bug fixing task to the developers who committed the bug inducing changes or enables developers to fix bugs by reverting these changes. Our study further identifies that change logs and the naturally small granularity of changes can help boost the performance of IR-based bug localization. Motivated by these observations, we propose an IR-based approach Locus to locate bugs from software changes, and evaluate it on six large open source projects. The results show that Locus outperforms existing techniques at the source file level localization significantly. MAP and MRR in particular have been improved, on average, by 20.1% and 20.5%, respectively. Locus is also capable of locating the inducing changes within top 5 for 41.0% of the bugs. The results show that Locus can significantly reduce the number of lines needing to be scanned to locate the bug compared with existing techniques.","tags":["Bug localization","Software changes","Information retrieval","Software analytics"],"title":"Locus: locating bugs from software changes","type":"publication"},{"authors":["Rongxin Wu","Xiao Xiao","Shing-Chi Cheung","Hongyu Zhang","Charles Zhang"],"categories":null,"content":" ","date":1452470400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1452470400,"objectID":"1b594f6e0e7c2a563bf0bb5cf7d1cdf0","permalink":"https://s-cube-xmu.github.io/zh/publication/casper-2016/","publishdate":"2016-01-11T00:00:00Z","relpermalink":"/zh/publication/casper-2016/","section":"publication","summary":"Call traces, i.e., sequences of function calls and returns, are fundamental to a wide range of program analyses such as bug reproduction, fault diagnosis, performance analysis, and many others. The conventional approach to collect call traces that instruments each function call and return site incurs large space and time overhead. Our approach aims at reducing the recording overheads by instrumenting only a small amount of call sites while keeping the capability of recovering the full trace. We propose a call trace model and a logged call trace model based on an LL(1) grammar, which enables us to define the criteria of a feasible solution to call trace collection. Based on the two models, we prove that to collect call traces with minimal instrumentation is an NP-hard problem. We then propose an efficient approach to obtaining a suboptimal solution. We implemented our approach as a tool Casper and evaluated it using the DaCapo benchmark suite. The experiment results show that our approach causes significantly lower runtime (and space) overhead than two state-of-the-arts approaches.","tags":["Call Trace","Instrumentation","Overhead"],"title":"Casper: an efficient approach to call trace collection","type":"publication"},{"authors":["Rongxin Wu"],"categories":null,"content":" ","date":1415664e3,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1415664e3,"objectID":"720f08e21f8685f2c19bbe1bd01f8445","permalink":"https://s-cube-xmu.github.io/zh/publication/diagnose-2014/","publishdate":"2014-11-11T00:00:00Z","relpermalink":"/zh/publication/diagnose-2014/","section":"publication","summary":"Software crashes are severe manifestations of software faults. Especially, software crashes in production software usually result in bad user experiences. Therefore, crashing faults mostly are required to be fixed with a high priority. Diagnosing crashing faults on production software is non-trivial, due to the characteristics of production environment. In general, it is required to address two major challenges. First, crash reports in production software are usually numerous, since production software is used by a large number of end users in various environments and configurations. Especially, a single fault may manifest as different crash reports, which makes the prioritizing debugging and understanding faults difficult. Second, deployed software is required to run with minimal overhead and cannot afford a heavyweight instrumentation approach to collect program execution information. Furthermore, end users require that the logged information should not reveal sensitive production data. This thesis contributes for developing crashing fault diagnosis tools that can be used in production environment.","tags":["Crash stack","Software crash","Statistical debugging","Software analytics"],"title":"Diagnose Crashing Faults on Production Software","type":"publication"},{"authors":["Rongxin Wu","Hongyu Zhang","Shing-Chi Cheung","Sunghun Kim"],"categories":null,"content":" ","date":1405900800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1405900800,"objectID":"c8f21ad95608e1acec737b9bf5f4fc24","permalink":"https://s-cube-xmu.github.io/zh/publication/crashlocator-2014/","publishdate":"2014-07-21T00:00:00Z","relpermalink":"/zh/publication/crashlocator-2014/","section":"publication","summary":"Software crash is common. When a crash occurs, software developers can receive a report upon user permission. A crash report typically includes a call stack at the time of crash. An important step of debugging a crash is to identify faulty functions, which is often a tedious and labor-intensive task. In this paper, we propose CrashLocator, a method to locate faulty functions using the crash stack information in crash reports. It deduces possible crash traces (the failing execution traces that lead to crash) by expanding the crash stack with functions in static call graph. It then calculates the suspiciousness of each function in the approximate crash traces. The functions are then ranked by their suspiciousness scores and are recommended to developers for further investigation. We evaluate our approach using real-world Mozilla crash data. The results show that our approach is effective: we can locate 50.6%, 63.7% and 67.5% of crashing faults by examining top 1, 5 and 10 functions recommended by CrashLocator, respectively. Our approach outperforms the conventional stack-only methods significantly.","tags":["Crashing fault localization","Crash stack","Software crash","Statistical debugging","Software analytics"],"title":"CrashLocator: locating crashing faults based on crash stacks","type":"publication"},{"authors":["Yingnong Dang","Rongxin Wu","Hongyu Zhang","Dongmei Zhang","Peter Nobel"],"categories":null,"content":" ","date":1338595200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1338595200,"objectID":"d2b416caa1a38db155dfa05d8b0c4520","permalink":"https://s-cube-xmu.github.io/zh/publication/rebucket-2012/","publishdate":"2012-06-02T00:00:00Z","relpermalink":"/zh/publication/rebucket-2012/","section":"publication","summary":"Software often crashes. Once a crash happens, a crash report could be sent to software developers for investigation upon user permission. To facilitate efficient handling of crashes, crash reports received by Microsoft's Windows Error Reporting (WER) system are organized into a set of “buckets”. Each bucket contains duplicate crash reports that are deemed as manifestations of the same bug. The bucket information is important for prioritizing efforts to resolve crashing bugs. To improve the accuracy of bucketing, we propose ReBucket, a method for clustering crash reports based on call stack matching. ReBucket measures the similarities of call stacks in crash reports and then assigns the reports to appropriate buckets based on the similarity values. We evaluate ReBucket using crash data collected from five widely-used Microsoft products. The results show that ReBucket achieves better overall performance than the existing methods. On average, the F-measure obtained by ReBucket is about 0.88.","tags":["Crash reports","Clustering;","Duplicate crash report detection;","Call stack trace;","WER"],"title":"ReBucket: A method for clustering duplicate crash reports based on call stack similarity","type":"publication"},{"authors":["Ming Li","Hongyu Zhang","Rongxin Wu","Zhi-Hua Zhou"],"categories":null,"content":" ","date":1338508800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1338508800,"objectID":"e2d1575913a42f984c7c712ddfb92e74","permalink":"https://s-cube-xmu.github.io/zh/publication/sample-based-software-defect-prediction-with-active-and-semi-supervised-learning-2012/","publishdate":"2012-06-01T00:00:00Z","relpermalink":"/zh/publication/sample-based-software-defect-prediction-with-active-and-semi-supervised-learning-2012/","section":"publication","summary":"Software defect prediction can help us better understand and control software quality. Current defect prediction techniques are mainly based on a sufficient amount of historical project data. However, historical data is often not available for new projects and for many organizations. In this case, effective defect prediction is difficult to achieve. To address this problem, we propose sample-based methods for software defect prediction. For a large software system, we can select and test a small percentage of modules, and then build a defect prediction model to predict defect-proneness of the rest of the modules. In this paper, we describe three methods for selecting a sample: random sampling with conventional machine learners, random sampling with a semi-supervised learner and active sampling with active semi-supervised learner. To facilitate the active sampling, we propose a novel active semi-supervised learning method ACoForest which is able to sample the modules that are most helpful for learning a good prediction model. Our experiments on PROMISE datasets show that the proposed methods are effective and have potential to be applied to industrial practice.","tags":["crash-inducing change","software crash","crash stack","bug localization"],"title":"Sample-based software defect prediction with active and semi-supervised learning","type":"publication"},{"authors":["Rongxin Wu","Hongyu Zhang","Sunghun Kim","S.C. Cheung"],"categories":null,"content":" ","date":1315526400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1315526400,"objectID":"b8a0bfdf7960452277889ae4343590eb","permalink":"https://s-cube-xmu.github.io/zh/publication/relink-2011/","publishdate":"2011-09-09T00:00:00Z","relpermalink":"/zh/publication/relink-2011/","section":"publication","summary":"Software defect information, including links between bugs and committed changes, plays an important role in software maintenance such as measuring quality and predicting defects. Usually, the links are automatically mined from change logs and bug reports using heuristics such as searching for specific keywords and bug IDs in change logs. However, the accuracy of these heuristics depends on the quality of change logs. Bird et al. found that there are many missing links due to the absence of bug references in change logs. They also found that the missing links lead to biased defect information, and it affects defect prediction performance. We manually inspected the explicit links, which have explicit bug IDs in change logs and observed that the links exhibit certain features. Based on our observation, we developed an automatic link recovery algorithm, ReLink, which automatically learns criteria of features from explicit links to recover missing links. We applied ReLink to three open source projects. ReLink reliably identified links with 89% precision and 78% recall on average, while the traditional heuristics alone achieve 91% precision and 64% recall. We also evaluated the impact of recovered links on software maintainability measurement and defect prediction, and found the results of ReLink yields significantly better accuracy than those of traditional heuristics.","tags":["Mining software repository","Missing links","Data quality","Bugs","Changes"],"title":"ReLink: recovering links between bugs and changes","type":"publication"},{"authors":["Sunghun Kim","Hongyu Zhang","Rongxin Wu","Liang Gong"],"categories":null,"content":" ","date":1305936e3,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1305936e3,"objectID":"29464cb8b05aba30b4da052dee132b39","permalink":"https://s-cube-xmu.github.io/zh/publication/dealing-2011/","publishdate":"2011-05-21T00:00:00Z","relpermalink":"/zh/publication/dealing-2011/","section":"publication","summary":"Many software defect prediction models have been built using historical defect data obtained by mining software repositories (MSR). Recent studies have discovered that data so collected contain noises because current defect collection practices are based on optional bug fix keywords or bug report links in change logs. Automatically collected defect data based on the change logs could include noises.\nThis paper proposes approaches to deal with the noise in defect data. First, we measure the impact of noise on defect prediction models and provide guidelines for acceptable noise level. We measure noise resistant ability of two well-known defect prediction algorithms and find that in general, for large defect datasets, adding FP (false positive) or FN (false negative) noises alone does not lead to substantial performance differences. However, the prediction performance decreases significantly when the dataset contains 20%-35% of both FP and FN noises. Second, we propose a noise detection and elimination algorithm to address this problem. Our empirical study shows that our algorithm can identify noisy instances with reasonable accuracy. In addition, after eliminating the noises using our algorithm, defect prediction accuracy is improved.","tags":["Defect prediction","Noise resistance","Buggy changes","Buggy files","Data quality"],"title":"Dealing with noise in defect prediction","type":"publication"},{"authors":["Hongyu Zhang and Rongxin Wu"],"categories":null,"content":" ","date":1284249600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1284249600,"objectID":"9aa4d3eec46cc228ec2020bc3e2ab771","permalink":"https://s-cube-xmu.github.io/zh/publication/sampling-program-quality-2010/","publishdate":"2010-09-12T00:00:00Z","relpermalink":"/zh/publication/sampling-program-quality-2010/","section":"publication","summary":"Many modern software systems are large, consisting of hundreds or even thousands of programs (source files). Understanding the overall quality of these programs is a resource and time-consuming activity. It is desirable to have a quick yet accurate estimation of the overall program quality in a cost-effective manner. In this paper, we propose a sampling based approach - for a large software project, we only sample a small percentage of source files, and then estimate the quality of the entire programs in the project based on the characteristics of the sample. Through experiments on public defect datasets, we show that we can successfully estimate the total number of defects, proportions of defective programs, defect distributions, and defect-proneness - all from a small sample of programs. Our experiments also show that small samples can achieve similar prediction accuracies as larger samples do.","tags":["Sampling","program quality","software quality assurance","defect prediction","statistical quality control"],"title":"Sampling program quality","type":"publication"},{"authors":["Ying Wang","Ming Wen","Zhenwei Liu","Rongxin Wu","Rui Wang","Bo Yang","Hai Yu","Zhiliang Zhu","Shing-Chi Cheung"],"categories":null,"content":" ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"eac93ed1d1c1758fcf19b6d1866a2070","permalink":"https://s-cube-xmu.github.io/zh/publication/do-the-dep-2018/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/publication/do-the-dep-2018/","section":"publication","summary":"Intensive dependencies of a Java project on third-party libraries can easily lead to the presence of multiple library or class versions on its classpath. When this happens, JVM will load one version and shadows the others. Dependency conflict (DC) issues occur when the loaded version fails to cover a required feature (e.g., method) referenced by the project, thus causing runtime exceptions. However, the warnings of duplicate classes or libraries detected by existing build tools such as Maven can be benign since not all instances of duplication will induce runtime exceptions, and hence are often ignored by developers. In this paper, we conducted an empirical study on real-world DC issues collected from large open source projects. We studied the manifestation and fixing patterns of DC issues. Based on our findings, we designed Decca, an automated detection tool that assesses DC issues' severity and filters out the benign ones. Our evaluation results on 30 projects show that Decca achieves a precision of 0.923 and recall of 0.766 in detecting high-severity DC issues. Decca also detected new DC issues in these projects. Subsequently, 20 DC bug reports were filed, and 11 of them were confirmed by developers. Issues in 6 reports were fixed with our suggested patches.","tags":["static analysis","Empirical study","third party library"],"title":"Do the Dependency Conflicts in My Project Matter?","type":"publication"}]